# Week 10 - Robotics

## What makes a robot?
- they are programmable machines capable of carrying out a series of actions autonomously or semi-autonomously
- they can be controlled externally or operate based on pre-defined instructions
- robot ethics is an interdisciplinary field that examines the moral and ethical implications of designing, creating, and using robots

## Robots in Australia
**Australia's National Robotics Strategy**

1. National capability
    - Australia has a strong, collaborative robotics and automation ecosystem that is recognised for its strengths, has a thriving domestic market and exports globally

2. Increasing adoption
    - Australian industries are supported to integrate robotics and automation technologies into their operations in ways that benefit Australian workers and communities

3. Trust, inclusion and responsible design/use
    - robotics and automation technologies designed and adopted in Australia are safe to use alongside Australian workers, and are secure and inclusive by design

4. Skills and diversity
    - Australians from all backgrouns contribute to and benefit from the development and adoption of robotics and automation


## Benefits and Considerations 

| Benefits | Ethical questions |
|---|---|
| - Replacing humans in dangerous tasks<br>- Increasing task precision and accuracy<br>- Improving environmental and financial efficiency<br>- Appealing to human interest | - Killer robots (autonomous weapons)<br>- Robot rights — e.g., work, decommissioning<br>- Legal and social accountability<br>- Human–robot relationships (e.g., military, caregiving)<br>- Safety and control |

## Safety Risks in Robotics
- Sensor errors and limitations
- Physical risks from machinery at scale
- Real-time decisions (reliant on stable energy, high computational power and efficient algorithms)
- Privacy and cybersecurity vulnerabilities
- AI-controlled robotics systems are vulnerable to bias
- Managing variables in complex, dynamic environments
- Trust/fear from anthropomorphism

## Safety
- at its most basic is simply protecting life and property from harm
- safety in AI is about controlling risks to a level that is deemed acceptable

### How can we achieve safety in autonomous robotics?
1. Regulation
    - impact of transitions towards safe robotics design and safe strong autonomous models

2. Supervision
    - human-in-the-loop, human-on-the-loop, human-out-of-the-loop

3. Value Alignment
    - ensuring AI systems' goals and behaviours align with human values and ethics

4. Responsible Deployment
    - thorough testing, monitoring, and evaluation of AI systems in real-world settings to ensure they operate safely and ethically

5. Transparency
    - clear communication about how AI systems work, their decision-making processes, and their limitations to build trust and understanding among users and stakeholders


## Autonomy and Control
- control is already challenging with narrow AI and it will be much worse in the case of superintelligent AI
- challenges include:
    - Orthogonality thesis: any level of intelligence is compatible with any goal, no reason to assume our values will be aligned simply because a machine is intelligent
    - Instrumental Convergence thesis: AGO will display self-improvement, self-preservation and resource acquisition to achieve its goals
    - Intelligibility and supervision: how do we produce scalable control?

## Value Alignment in Ai
- it is the challenge of ensuring that AI systems' goals and behaviours align with human values and ethics

- Top-down approach:
    - explicitly program ethical principles and rules into AI systems
    - e.g., Asimov's Three Laws of Robotics

- Bottom-up approach:
    - use machine learning to allow AI systems to learn ethical behaviour from data and experience

- Models: 
    - Instructions: the agent is given explicit instructions on what to do
    - Expressed intentions: the agent does what I intend it to do
    - Revealed preferences: the agent does what my behaviour reveals I prefer
    - Informed preferences: the agent does what I would want it to do if I were rational and informed
    - Interest or wellbeing: the agent does what is best for me
